{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lenet-mnist-swift-models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbolella/s4tf-lenet-mnist/blob/master/lenet_mnist_swift_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TQjRmPLaGT2",
        "colab_type": "text"
      },
      "source": [
        "# LeNet-5 & MNIST using Swift for Tensorflow\n",
        "by Danny Bolella\n",
        "\n",
        "Edit: Updated to use Swift for Tensorflow v. 0.6\n",
        "\n",
        "To learn more about how this Colab works, check out the associated Medium article at: https://heartbeat.fritz.ai/swifty-ml-an-intro-to-swift-for-tensorflow-9edc7045bc0c\n",
        "\n",
        "This Colab is a reworking of the official S4TF Example found at: https://github.com/tensorflow/swift-models/tree/master/Examples/LeNet-MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MckWj_xja0Ru",
        "colab_type": "text"
      },
      "source": [
        "## Installing and Importing Libraries\n",
        "First, we pull in 2 libraries as swift packages from the official S4TF models repo.  We use `%install` to accomplish this.  Once complete, we then import the libraries we'll be using (Tensorflow is already available on Colab, no need to install)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDnsjoqvB1g_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "8476c9fb-3777-4119-b5ba-7026c6766835"
      },
      "source": [
        "%install '.package(url: \"https://github.com/tensorflow/swift-models.git\", .branch(\"master\"))' ImageClassificationModels Datasets\n",
        "\n",
        "import TensorFlow\n",
        "import Datasets\n",
        "import ImageClassificationModels"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages:\n",
            "\t.package(url: \"https://github.com/tensorflow/swift-models.git\", .branch(\"master\"))\n",
            "\t\tImageClassificationModels\n",
            "\t\tDatasets\n",
            "With SwiftPM flags: []\n",
            "Working in: /tmp/tmp_82lvl7h/swift-install\n",
            "Fetching https://github.com/tensorflow/swift-models.git\n",
            "Fetching https://github.com/kylef/Commander.git\n",
            "Fetching https://github.com/kylef/Spectre.git\n",
            "Cloning https://github.com/tensorflow/swift-models.git\n",
            "Resolving https://github.com/tensorflow/swift-models.git at master\n",
            "Cloning https://github.com/kylef/Commander.git\n",
            "Resolving https://github.com/kylef/Commander.git at 0.9.1\n",
            "Cloning https://github.com/kylef/Spectre.git\n",
            "Resolving https://github.com/kylef/Spectre.git at 0.9.0\n",
            "[1/14] Compiling ModelSupport Stderr.swift\n",
            "[2/14] Compiling ImageClassificationModels DenseNet121.swift\n",
            "[3/14] Compiling ModelSupport Image.swift\n",
            "[4/15] Merging module ModelSupport\n",
            "[5/20] Compiling Datasets LabeledExample.swift\n",
            "[6/20] Compiling Datasets MNIST.swift\n",
            "[7/20] Compiling Datasets CIFAR10.swift\n",
            "[8/20] Compiling Datasets DatasetUtilities.swift\n",
            "[9/20] Compiling Datasets ImageClassificationDataset.swift\n",
            "[10/21] Merging module Datasets\n",
            "[11/21] Wrapping AST for ModelSupport for debugging\n",
            "[12/21] Wrapping AST for Datasets for debugging\n",
            "[18/21] Compiling ImageClassificationModels WideResNet.swift\n",
            "[19/22] Merging module ImageClassificationModels\n",
            "[20/23] Wrapping AST for ImageClassificationModels for debugging\n",
            "[21/23] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
            "[22/24] Merging module jupyterInstalledPackages\n",
            "[23/24] Wrapping AST for jupyterInstalledPackages for debugging\n",
            "[24/24] Linking libjupyterInstalledPackages.so\n",
            "Initializing Swift...\n",
            "Installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR-XcJygbCM4",
        "colab_type": "text"
      },
      "source": [
        "## Model, Dataset, Optimizer... Oh My!\n",
        "Next, we instantiate the dataset, model, and optimizer we will be using.  We also setup our epochCount (the number of times we'll train our model) and batchSize (how much data we'll train with at a time).\n",
        "\n",
        "One last thing to do is setup our test data into batches using our designated batchSize.\n",
        "\n",
        "*Note: if this code block hangs, break out the calls here into separate code blocks, restart runtimes, and re-run the notebook each codeblock at a time.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN5sL1KJFk-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6dae7fbb-bcaf-41b1-9539-d2ab3d51fa98"
      },
      "source": [
        "let epochCount = 12\n",
        "\n",
        "let batchSize = 128\n",
        "\n",
        "let dataset = MNIST()\n",
        "\n",
        "var model = LeNet()\n",
        "\n",
        "let optimizer = SGD(for: model, learningRate: 0.1)\n",
        "\n",
        "let testBatches = dataset.testDataset.batched(batchSize)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading resource: train-images-idx3-ubyte\r\n",
            "Loading local data at: /content/train-images-idx3-ubyte\n",
            "Succesfully loaded resource: train-images-idx3-ubyte\n",
            "Loading resource: train-labels-idx1-ubyte\n",
            "Loading local data at: /content/train-labels-idx1-ubyte\n",
            "Succesfully loaded resource: train-labels-idx1-ubyte\n",
            "Loading resource: t10k-images-idx3-ubyte\n",
            "Loading local data at: /content/t10k-images-idx3-ubyte\n",
            "Succesfully loaded resource: t10k-images-idx3-ubyte\n",
            "Loading resource: t10k-labels-idx1-ubyte\n",
            "Loading local data at: /content/t10k-labels-idx1-ubyte\n",
            "Succesfully loaded resource: t10k-labels-idx1-ubyte\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo6dX8-cdM4g",
        "colab_type": "text"
      },
      "source": [
        "## Benchmarking Prep\n",
        "Lastly, we create a `struct` that we will use to hold our training and testing benchmarks per epoch.  Note that we also have a function in our struct to update our `GuessCount` stats.  This eliminates duplicate code in our training and testing loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDZZ_NMxdNSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "struct Statistics {\n",
        "    var correctGuessCount: Int = 0\n",
        "    var totalGuessCount: Int = 0\n",
        "    var totalLoss: Float = 0\n",
        "    \n",
        "    mutating func updateGuessCounts(logits: Tensor<Float>, labels: Tensor<Int32>, batchSize: Int) {\n",
        "      let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n",
        "      self.correctGuessCount += Int(\n",
        "            Tensor<Int32>(correctPredictions).sum().scalarized())\n",
        "      self.totalGuessCount += batchSize\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErIX2Bc7bUly",
        "colab_type": "text"
      },
      "source": [
        "## Training Day\n",
        "Lastly, we run our training!  We run the training loop based on our `epochCount`.  Each time we do, we loop through batches of our data, run it through our model, update our benchmarks, and optimize along the gradients.  \n",
        "\n",
        "At the end of each epoch, we print out our benchmark data.  We should see our loss decrease and our accuracy increase with each pass of training our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfcjc7vYlcpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "2735e975-ae9a-4c12-d92a-5a1f846454ec"
      },
      "source": [
        "print(\"Beginning training...\")\n",
        "\n",
        "// The training loop.\n",
        "for epoch in 1...epochCount {\n",
        "    var trainStats = Statistics()\n",
        "    var testStats = Statistics()\n",
        "    let trainingShuffled = dataset.trainingDataset.shuffled(\n",
        "        sampleCount: dataset.trainingExampleCount, randomSeed: Int64(epoch))\n",
        "    Context.local.learningPhase = .training\n",
        "    for batch in trainingShuffled.batched(batchSize) {\n",
        "        let (labels, images) = (batch.label, batch.data)\n",
        "        // Compute the gradient with respect to the model.\n",
        "        let (loss, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
        "            let logits = model(images)\n",
        "            trainStats.updateGuessCounts(logits: logits, labels: labels, batchSize: batchSize)\n",
        "            return softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "        }\n",
        "        trainStats.totalLoss += loss.scalarized()\n",
        "        optimizer.update(&model, along: gradients)\n",
        "    }\n",
        "\n",
        "    Context.local.learningPhase = .inference\n",
        "    for batch in testBatches {\n",
        "        let (labels, images) = (batch.label, batch.data)\n",
        "        // Compute loss on test set\n",
        "        let logits = model(images)\n",
        "        testStats.updateGuessCounts(logits: logits, labels: labels, batchSize: batchSize)\n",
        "        let loss = softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "        testStats.totalLoss += loss.scalarized()\n",
        "    }\n",
        "\n",
        "    let trainAccuracy = Float(trainStats.correctGuessCount) / Float(trainStats.totalGuessCount)\n",
        "    let testAccuracy = Float(testStats.correctGuessCount) / Float(testStats.totalGuessCount)\n",
        "    print(\"\"\"\n",
        "          [Epoch \\(epoch)] \\\n",
        "          Training Loss: \\(trainStats.totalLoss), \\\n",
        "          Training Accuracy: \\(trainStats.correctGuessCount)/\\(trainStats.totalGuessCount) \\\n",
        "          (\\(trainAccuracy)), \\\n",
        "          Test Loss: \\(testStats.totalLoss), \\\n",
        "          Test Accuracy: \\(testStats.correctGuessCount)/\\(testStats.totalGuessCount) \\\n",
        "          (\\(testAccuracy))\n",
        "          \"\"\")\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "[Epoch 1] Training Loss: 224.62172, Training Accuracy: 51032/60032 (0.85007995), Test Loss: 10.67791, Test Accuracy: 9563/10112 (0.9457081)\n",
            "[Epoch 2] Training Loss: 53.248043, Training Accuracy: 57909/60032 (0.96463555), Test Loss: 6.694432, Test Accuracy: 9737/10112 (0.96291536)\n",
            "[Epoch 3] Training Loss: 37.35574, Training Accuracy: 58520/60032 (0.97481346), Test Loss: 4.70572, Test Accuracy: 9805/10112 (0.96964)\n",
            "[Epoch 4] Training Loss: 30.11113, Training Accuracy: 58841/60032 (0.9801606), Test Loss: 4.8403378, Test Accuracy: 9817/10112 (0.97082675)\n",
            "[Epoch 5] Training Loss: 25.07181, Training Accuracy: 59017/60032 (0.98309237), Test Loss: 3.5734432, Test Accuracy: 9849/10112 (0.9739913)\n",
            "[Epoch 6] Training Loss: 21.899233, Training Accuracy: 59100/60032 (0.98447496), Test Loss: 4.1357136, Test Accuracy: 9824/10112 (0.971519)\n",
            "[Epoch 7] Training Loss: 19.437084, Training Accuracy: 59222/60032 (0.9865072), Test Loss: 3.4082255, Test Accuracy: 9852/10112 (0.974288)\n",
            "[Epoch 8] Training Loss: 16.878239, Training Accuracy: 59334/60032 (0.98837286), Test Loss: 3.2727385, Test Accuracy: 9861/10112 (0.975178)\n",
            "[Epoch 9] Training Loss: 15.335546, Training Accuracy: 59372/60032 (0.98900586), Test Loss: 3.6553814, Test Accuracy: 9857/10112 (0.9747824)\n",
            "[Epoch 10] Training Loss: 13.779181, Training Accuracy: 59442/60032 (0.9901719), Test Loss: 3.8226461, Test Accuracy: 9849/10112 (0.9739913)\n",
            "[Epoch 11] Training Loss: 12.836036, Training Accuracy: 59467/60032 (0.99058837), Test Loss: 3.1440644, Test Accuracy: 9874/10112 (0.9764636)\n",
            "[Epoch 12] Training Loss: 11.369085, Training Accuracy: 59545/60032 (0.9918877), Test Loss: 2.9921978, Test Accuracy: 9874/10112 (0.9764636)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbrylhslosv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}