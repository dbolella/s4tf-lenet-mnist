{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lenet-mnist-swift-models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbolella/s4tf-lenet-mnist/blob/master/lenet_mnist_swift_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TQjRmPLaGT2",
        "colab_type": "text"
      },
      "source": [
        "# LeNet-5 & MNIST using Swift for Tensorflow\n",
        "by Danny Bolella\n",
        "\n",
        "To learn more about how this Colab works, check out the associated Medium article at: \n",
        "\n",
        "This Colab is a reworking of the official S4TF Example found at: https://github.com/tensorflow/swift-models/tree/master/Examples/LeNet-MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MckWj_xja0Ru",
        "colab_type": "text"
      },
      "source": [
        "## Installing and Importing Libraries\n",
        "First, we pull in 2 libraries as swift packages from the official S4TF models repo.  We use `%install` to accomplish this.  Once complete, we then import the libraries we'll be using (Tensorflow is already available on Colab, no need to install)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDnsjoqvB1g_",
        "colab_type": "code",
        "outputId": "ca3841a6-32f2-4aaf-9361-cad75c83c939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "%install '.package(url: \"https://github.com/tensorflow/swift-models.git\", .branch(\"master\"))' ImageClassificationModels Datasets\n",
        "\n",
        "import TensorFlow\n",
        "import Datasets\n",
        "import ImageClassificationModels"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages:\n",
            "\t.package(url: \"https://github.com/tensorflow/swift-models.git\", .branch(\"master\"))\n",
            "\t\tImageClassificationModels\n",
            "\t\tDatasets\n",
            "With SwiftPM flags: []\n",
            "Working in: /tmp/tmptn8w0m2q/swift-install\n",
            "Fetching https://github.com/tensorflow/swift-models.git\n",
            "Cloning https://github.com/tensorflow/swift-models.git\n",
            "Resolving https://github.com/tensorflow/swift-models.git at master\n",
            "[1/11] Compiling ImageClassificationModels DenseNet121.swift\n",
            "[2/11] Compiling ImageClassificationModels LeNet-5.swift\n",
            "[3/11] Compiling Datasets DatasetUtilities.swift\n",
            "[4/11] Compiling Datasets MNIST.swift\n",
            "[5/12] Merging module Datasets\n",
            "[10/12] Compiling ImageClassificationModels SqueezeNet.swift\n",
            "[11/12] Compiling ImageClassificationModels WideResNet.swift\n",
            "[12/13] Merging module ImageClassificationModels\n",
            "[13/14] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
            "[14/15] Merging module jupyterInstalledPackages\n",
            "[15/15] Linking libjupyterInstalledPackages.so\n",
            "Initializing Swift...\n",
            "Installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR-XcJygbCM4",
        "colab_type": "text"
      },
      "source": [
        "## Model, Dataset, Optimizer... Oh My!\n",
        "Next, we instantiate the dataset, model, and optimizer we will be using.  We also setup our epochCount (the number of times we'll train our model) and batchSize (how much data we'll train with at a time)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN5sL1KJFk-d",
        "colab_type": "code",
        "outputId": "c6670e8b-d82a-4d48-e55e-f42653555150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "let batchSize = 128\n",
        "\n",
        "let dataset = MNIST(batchSize: batchSize)\n",
        "\n",
        "var model = LeNet()\n",
        "\n",
        "let optimizer = SGD(for: model, learningRate: 0.1)\n",
        "\n",
        "let epochCount = 12"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading resource: train-images-idx3-ubyte\r\n",
            "Loading local data at: /content/train-images-idx3-ubyte\n",
            "Succesfully loaded resource: train-images-idx3-ubyte\n",
            "Loading resource: train-labels-idx1-ubyte\n",
            "Loading local data at: /content/train-labels-idx1-ubyte\n",
            "Succesfully loaded resource: train-labels-idx1-ubyte\n",
            "Loading resource: t10k-images-idx3-ubyte\n",
            "Loading local data at: /content/t10k-images-idx3-ubyte\n",
            "Succesfully loaded resource: t10k-images-idx3-ubyte\n",
            "Loading resource: t10k-labels-idx1-ubyte\n",
            "Loading local data at: /content/t10k-labels-idx1-ubyte\n",
            "Succesfully loaded resource: t10k-labels-idx1-ubyte\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo6dX8-cdM4g",
        "colab_type": "text"
      },
      "source": [
        "## Benchmarking Prep\n",
        "Lastly, we create a `struct` that we will use to hold our training and testing benchmarks per epoch.  Note that we also have a function in our struct to update our `GuessCount` stats.  This eliminates duplicate code in our training and testing loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDZZ_NMxdNSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "struct Statistics {\n",
        "    var correctGuessCount: Int = 0\n",
        "    var totalGuessCount: Int = 0\n",
        "    var totalLoss: Float = 0\n",
        "    \n",
        "    mutating func updateGuessCounts(logits: Tensor<Float>, labels: Tensor<Int32>, batchSize: Int) {\n",
        "      let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n",
        "      self.correctGuessCount += Int(\n",
        "            Tensor<Int32>(correctPredictions).sum().scalarized())\n",
        "      self.totalGuessCount += batchSize\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErIX2Bc7bUly",
        "colab_type": "text"
      },
      "source": [
        "## Training Day\n",
        "Lastly, we run our training!  We run the training loop based on our `epochCount`.  Each time we do, we loop through batches of our data, run it through our model, update our benchmarks, and optimize along the gradients.  \n",
        "\n",
        "At the end of each epoch, we print out our benchmark data.  We should see our loss decrease and our accuracy increase with each pass of training our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfcjc7vYlcpA",
        "colab_type": "code",
        "outputId": "f9add031-8b7f-4ecb-bcdf-9df4c59ee212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "print(\"Beginning training...\")\n",
        "\n",
        "// The training loop.\n",
        "for epoch in 1...epochCount {\n",
        "    var trainStats = Statistics()\n",
        "    var testStats = Statistics()\n",
        "    Context.local.learningPhase = .training\n",
        "    for i in 0 ..< dataset.trainingSize / batchSize {\n",
        "        let images = dataset.trainingImages.minibatch(at: i, batchSize: batchSize)\n",
        "        let labels = dataset.trainingLabels.minibatch(at: i, batchSize: batchSize)\n",
        "        // Compute the gradient with respect to the model.\n",
        "        let (loss, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
        "            let logits = model(images)\n",
        "            trainStats.updateGuessCounts(logits: logits, labels: labels, batchSize: batchSize)\n",
        "            return softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "        }\n",
        "        trainStats.totalLoss += loss.scalarized()\n",
        "        optimizer.update(&model, along: gradients)\n",
        "    }\n",
        "\n",
        "    Context.local.learningPhase = .inference\n",
        "    for i in 0 ..< dataset.testSize / batchSize {\n",
        "        let images = dataset.testImages.minibatch(at: i, batchSize: batchSize)\n",
        "        let labels = dataset.testLabels.minibatch(at: i, batchSize: batchSize)\n",
        "        // Compute loss on test set\n",
        "        let logits = model(images)\n",
        "        testStats.updateGuessCounts(logits: logits, labels: labels, batchSize: batchSize)\n",
        "        let loss = softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "        testStats.totalLoss += loss.scalarized()\n",
        "    }\n",
        "\n",
        "    let trainAccuracy = Float(trainStats.correctGuessCount) / Float(trainStats.totalGuessCount)\n",
        "    let testAccuracy = Float(testStats.correctGuessCount) / Float(testStats.totalGuessCount)\n",
        "    print(\"\"\"\n",
        "          [Epoch \\(epoch)] \\\n",
        "          Training Loss: \\(trainStats.totalLoss), \\\n",
        "          Training Accuracy: \\(trainStats.correctGuessCount)/\\(trainStats.totalGuessCount) \\\n",
        "          (\\(trainAccuracy)), \\\n",
        "          Test Loss: \\(testStats.totalLoss), \\\n",
        "          Test Accuracy: \\(testStats.correctGuessCount)/\\(testStats.totalGuessCount) \\\n",
        "          (\\(testAccuracy))\n",
        "          \"\"\")\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "[Epoch 1] Training Loss: 957.23724, Training Accuracy: 27154/59904 (0.45329192), Test Loss: 128.8437, Test Accuracy: 8156/9984 (0.81690705)\n",
            "[Epoch 2] Training Loss: 768.2697, Training Accuracy: 49305/59904 (0.8230669), Test Loss: 126.20526, Test Accuracy: 8441/9984 (0.8454527)\n",
            "[Epoch 3] Training Loss: 730.51227, Training Accuracy: 54220/59904 (0.9051148), Test Loss: 119.77396, Test Accuracy: 9282/9984 (0.9296875)\n",
            "[Epoch 4] Training Loss: 715.5964, Training Accuracy: 56055/59904 (0.9357472), Test Loss: 118.913506, Test Accuracy: 9367/9984 (0.9382011)\n",
            "[Epoch 5] Training Loss: 709.2892, Training Accuracy: 56851/59904 (0.9490351), Test Loss: 117.98292, Test Accuracy: 9490/9984 (0.9505208)\n",
            "[Epoch 6] Training Loss: 705.69525, Training Accuracy: 57249/59904 (0.95567906), Test Loss: 117.355515, Test Accuracy: 9567/9984 (0.9582332)\n",
            "[Epoch 7] Training Loss: 702.83966, Training Accuracy: 57592/59904 (0.9614049), Test Loss: 117.02219, Test Accuracy: 9603/9984 (0.96183896)\n",
            "[Epoch 8] Training Loss: 700.98676, Training Accuracy: 57810/59904 (0.9650441), Test Loss: 116.89666, Test Accuracy: 9644/9984 (0.96594554)\n",
            "[Epoch 9] Training Loss: 699.1939, Training Accuracy: 58067/59904 (0.96933424), Test Loss: 116.59748, Test Accuracy: 9660/9984 (0.9675481)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbrylhslosv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}